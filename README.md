# Awesome talking face generation

# papers & codes 

## 2021
- Visual Speech Enhancement Without A Real Visual Stream [[paper](https://openaccess.thecvf.com/content/WACV2021/papers/Hegde_Visual_Speech_Enhancement_Without_a_Real_Visual_Stream_WACV_2021_paper.pdf)]


## 2020
| title | - | paper | code | dataset |
| --- | ---| --- | --- | --- |
|A Lip Sync Expert Is All You Need for Speech to Lip Generation In The Wild | ACMMM|[paper](https://arxiv.org/pdf/2008.10010.pdf) |[code](https://github.com/Rudrabha/Wav2Lip) | LRS2 |
|Talking-head Generation with Rhythmic Head Motion |ECCV |[paper](https://arxiv.org/pdf/2007.08547.pdf) | [code](https://github.com/lelechen63/Talking-head-Generation-with-Rhythmic-Head-Motion)| VoxCeleb2,  LRW,  LRS3-TED |
|MEAD: A Large-scale Audio-visual Dataset for Emotional Talking-face Generation|ECCV | [paper](https://arxiv.org/pdf/1912.05566.pdf)| [code](https://wywu.github.io/projects/MEAD/support/MEAD.pdf)| VoxCeleb2, AffectNet |
|Neural voice puppetry:Audio-driven facial reenactment|ECCV  |[paper]()|[code]()| |
|HeadGAN:Video-and-Audio-Driven Talking Head Synthesis|-|[paper](https://arxiv.org/pdf/2012.08261v1.pdf)|-|VoxCeleb2|
|MakeItTalk: Speaker-Aware Talking Head Animation| |[paper](https://github.com/yzhou359/MakeItTalk)|[code](https://github.com/adobe-research/MakeItTalk), [code](https://github.com/yzhou359/MakeItTalk)| VoxCeleb2, VCTK |
|Audio-driven Talking Face Video Generation with Learning-based Personalized Head Pose |- |[paper](https://arxiv.org/pdf/2002.10137.pdf)|[code](https://github.com/yiranran/Audio-driven-TalkingFace-HeadPose)|  ImageNet,  FaceWarehouse,  LRW|
|Photorealistic Lip Sync with Adversarial Temporal Convolutional Networks| -|[paper](https://arxiv.org/pdf/2002.08700.pdf)|-| |
|SPEECH-DRIVEN FACIAL ANIMATION USING POLYNOMIAL FUSION OF FEATURES|-|[paper](https://arxiv.org/pdf/1912.05833.pdf)|-|LRW|
| | |[paper]()|[code]()| |
| | |[paper]()|[code]()| |
| | |[paper]()|[code]()| |
| | |[paper]()|[code]()| |

## 2019
| title | - | paper | code | dataset |
| --- | ---| --- | --- | --- |
| | |[paper]()|[code]()| |
| | |[paper]()|[code]()| |
| | |[paper]()|[code]()| |
## 2018

## datasets
- VoxCeleb [link](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/)
- LRS2 [link](https://www.robots.ox.ac.uk/~vgg/data/lip_reading/lrs2.html)
- LRW [link](https://www.robots.ox.ac.uk/~vgg/data/lip_reading/lrw1.html)
- GRID [link](http://spandh.dcs.shef.ac.uk/avlombard/)
- BIWI [link](https://data.vision.ee.ethz.ch/cvl/datasets/b3dac2.en.html)
- SAVEE [link](http://kahlan.eps.surrey.ac.uk/savee/Download.html)

## metrics
- PSNR (peak signal-to-noise ratio) 
- SSIM (structural similarity index measure)
- LMD (landmark distance error)
- LRA (lip-reading accuracy) [-](https://arxiv.org/pdf/1804.04786.pdf)
- FID (Fr√©chet inception distance) 
- LSE-D (Lip Sync Error - Distance)
- LSE-C (Lip Sync Error - Confidence) 

